{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "\n",
    "def tokenize(line):\n",
    "    line = line.replace(',', ' ')\n",
    "    line = line.replace('.', ' ')\n",
    "    line = line.replace('!', ' ')\n",
    "    line = line.replace('?', ' ')\n",
    "    line = line.replace('\\n', ' ')\n",
    "    line = line.replace(')', ' ')\n",
    "    line = line.replace('(', ' ')\n",
    "    line = line.replace(':', ' ')\n",
    "    line = line.replace(';', ' ')\n",
    "    line = line.replace('\"', ' ')\n",
    "    line = line.lower()\n",
    "    line = line.replace('ё', 'е')\n",
    "    words = mystem.lemmatize(line)\n",
    "    return list(filter(lambda x: x not in ' \\n-', words))[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=tokenize)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('train.txt') as data:\n",
    "        return data.readlines()\n",
    "    \n",
    "def load_test():\n",
    "    with open('test.txt') as data:\n",
    "        return data.readlines()\n",
    "\n",
    "def load_labels():\n",
    "    with open('labels.txt') as data:\n",
    "        return list(map(lambda x: float(x), data.readlines()))\n",
    "    \n",
    "labels = load_labels()\n",
    "    \n",
    "def load_dataset(f):\n",
    "    pairs = zip(f(), labels)\n",
    "    return list(map(lambda x: data.Example.fromlist(x, fields=[('text', TEXT), ('label', LABEL)]), pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data.Dataset(examples=load_dataset(load_data), fields=[('text', TEXT), ('label', LABEL)])\n",
    "test_data = data.Dataset(examples=load_dataset(load_test), fields=[('text', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = all_data.split(random_state = random.seed(GLOBAL_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 14000\n",
      "Number of validation examples: 6000\n",
      "{'text': ['боже', '  ', 'какой', 'нудятина', 'тоска', 'смертный'], 'label': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000 # cut top words for vectorization\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, min_freq=10)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('панда', 3), ('беззаботность', 3), ('буддийский', 3), ('уравновешивать', 3), ('правота', 3), ('воспитываться', 3), ('развлекуха', 3), ('романс', 3), ('неповоротливый', 3), ('            ', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10000)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "#         self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=1, bias=False, \n",
    "#                           dropout=0.33\n",
    "                         )\n",
    "#         self.rnn = nn.RNN(embedding_dim, hidden_dim, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "#         print('output', output.size())\n",
    "#         print('output -1', output[-1,:,:].size())\n",
    "#         print('hidden', hidden.squeeze(0).size())\n",
    "#         print()\n",
    "\n",
    "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "#         return self.fc(hidden.squeeze(0))\n",
    "        return self.fc(output[-1,:,:].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.004)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    rounded_y = torch.round(y)\n",
    "    equal = rounded_preds == rounded_y\n",
    "    \n",
    "    return torch.mean(equal.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 4.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 5.039 | Train Acc: 18.40%\n",
      "\t Val. Loss: 6.103 |  Validation Acc: 11.49%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 3.532 | Train Acc: 25.06%\n",
      "\t Val. Loss: 5.407 |  Validation Acc: 15.98%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 2.695 | Train Acc: 28.44%\n",
      "\t Val. Loss: 5.915 |  Validation Acc: 15.65%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 2.148 | Train Acc: 31.84%\n",
      "\t Val. Loss: 5.279 |  Validation Acc: 21.91%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 1.713 | Train Acc: 35.03%\n",
      "\t Val. Loss: 5.803 |  Validation Acc: 19.76%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 1.444 | Train Acc: 37.17%\n",
      "\t Val. Loss: 5.571 |  Validation Acc: 20.48%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 1.179 | Train Acc: 40.84%\n",
      "\t Val. Loss: 5.863 |  Validation Acc: 18.55%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 1.007 | Train Acc: 43.27%\n",
      "\t Val. Loss: 5.667 |  Validation Acc: 19.11%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 0.879 | Train Acc: 45.54%\n",
      "\t Val. Loss: 5.554 |  Validation Acc: 20.12%\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.780 | Train Acc: 48.19%\n",
      "\t Val. Loss: 5.748 |  Validation Acc: 21.05%\n",
      "Epoch: 11 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.684 | Train Acc: 51.25%\n",
      "\t Val. Loss: 5.493 |  Validation Acc: 19.77%\n",
      "Epoch: 12 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.665 | Train Acc: 51.39%\n",
      "\t Val. Loss: 5.607 |  Validation Acc: 19.99%\n",
      "Epoch: 13 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.618 | Train Acc: 52.13%\n",
      "\t Val. Loss: 5.555 |  Validation Acc: 21.02%\n",
      "Epoch: 14 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.588 | Train Acc: 52.52%\n",
      "\t Val. Loss: 6.069 |  Validation Acc: 18.07%\n",
      "Epoch: 15 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.533 | Train Acc: 55.17%\n",
      "\t Val. Loss: 6.023 |  Validation Acc: 17.85%\n",
      "Epoch: 16 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.506 | Train Acc: 56.31%\n",
      "\t Val. Loss: 5.961 |  Validation Acc: 18.12%\n",
      "Epoch: 17 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.483 | Train Acc: 57.45%\n",
      "\t Val. Loss: 5.829 |  Validation Acc: 19.68%\n",
      "Epoch: 18 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.434 | Train Acc: 59.77%\n",
      "\t Val. Loss: 6.018 |  Validation Acc: 18.84%\n",
      "Epoch: 19 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.432 | Train Acc: 60.39%\n",
      "\t Val. Loss: 5.874 |  Validation Acc: 19.82%\n",
      "Epoch: 20 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.471 | Train Acc: 58.29%\n",
      "\t Val. Loss: 6.041 |  Validation Acc: 18.16%\n",
      "Epoch: 21 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.499 | Train Acc: 57.41%\n",
      "\t Val. Loss: 5.635 |  Validation Acc: 18.19%\n",
      "Epoch: 22 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.480 | Train Acc: 57.37%\n",
      "\t Val. Loss: 5.501 |  Validation Acc: 20.11%\n",
      "Epoch: 23 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.481 | Train Acc: 57.17%\n",
      "\t Val. Loss: 5.561 |  Validation Acc: 19.70%\n",
      "Epoch: 24 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.477 | Train Acc: 58.05%\n",
      "\t Val. Loss: 5.401 |  Validation Acc: 20.27%\n",
      "Epoch: 25 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.475 | Train Acc: 57.74%\n",
      "\t Val. Loss: 5.600 |  Validation Acc: 17.80%\n",
      "Epoch: 26 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.499 | Train Acc: 56.85%\n",
      "\t Val. Loss: 5.450 |  Validation Acc: 20.08%\n",
      "Epoch: 27 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.539 | Train Acc: 55.44%\n",
      "\t Val. Loss: 5.777 |  Validation Acc: 17.77%\n",
      "Epoch: 28 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.507 | Train Acc: 57.09%\n",
      "\t Val. Loss: 5.594 |  Validation Acc: 20.47%\n",
      "Epoch: 29 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.492 | Train Acc: 57.54%\n",
      "\t Val. Loss: 5.759 |  Validation Acc: 19.93%\n",
      "Epoch: 30 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.515 | Train Acc: 55.89%\n",
      "\t Val. Loss: 5.789 |  Validation Acc: 18.72%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "# model.load_state_dict(torch.load('model1.pt'))\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model1.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n",
      "6\n",
      "2\n",
      "8\n",
      "3\n",
      "4\n",
      "9\n",
      "6\n",
      "7\n",
      "9\n",
      "6\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "9\n",
      "5\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "4\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "1\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "2\n",
      "5\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "5\n",
      "8\n",
      "10\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "9\n",
      "6\n",
      "10\n",
      "4\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "4\n",
      "9\n",
      "7\n",
      "9\n",
      "6\n",
      "6\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "11\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "8\n",
      "1\n",
      "8\n",
      "9\n",
      "8\n",
      "6\n",
      "2\n",
      "3\n",
      "9\n",
      "9\n",
      "7\n",
      "2\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "5\n",
      "7\n",
      "3\n",
      "7\n",
      "7\n",
      "3\n",
      "4\n",
      "8\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "9\n",
      "6\n",
      "8\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "9\n",
      "9\n",
      "5\n",
      "8\n",
      "7\n",
      "2\n",
      "9\n",
      "7\n",
      "9\n",
      "10\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "8\n",
      "9\n",
      "7\n",
      "10\n",
      "8\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "7\n",
      "9\n",
      "4\n",
      "10\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "5\n",
      "10\n",
      "3\n",
      "8\n",
      "2\n",
      "5\n",
      "9\n",
      "8\n",
      "6\n",
      "8\n",
      "7\n",
      "5\n",
      "8\n",
      "8\n",
      "3\n",
      "9\n",
      "6\n",
      "9\n",
      "10\n",
      "7\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "8\n",
      "3\n",
      "7\n",
      "8\n",
      "8\n",
      "4\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "10\n",
      "7\n",
      "9\n",
      "3\n",
      "9\n",
      "4\n",
      "8\n",
      "2\n",
      "9\n",
      "10\n",
      "9\n",
      "7\n",
      "9\n",
      "3\n",
      "10\n",
      "8\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "7\n",
      "8\n",
      "8\n",
      "1\n",
      "7\n",
      "6\n",
      "8\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "10\n",
      "7\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "8\n",
      "10\n",
      "9\n",
      "6\n",
      "7\n",
      "4\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "7\n",
      "3\n",
      "10\n",
      "7\n",
      "9\n",
      "1\n",
      "5\n",
      "8\n",
      "9\n",
      "5\n",
      "9\n",
      "5\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "7\n",
      "10\n",
      "10\n",
      "9\n",
      "7\n",
      "9\n",
      "6\n",
      "10\n",
      "10\n",
      "9\n",
      "3\n",
      "3\n",
      "9\n",
      "8\n",
      "8\n",
      "11\n",
      "10\n",
      "8\n",
      "5\n",
      "6\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "11\n",
      "7\n",
      "10\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "10\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "8\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "3\n",
      "6\n",
      "8\n",
      "9\n",
      "6\n",
      "8\n",
      "9\n",
      "11\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "10\n",
      "6\n",
      "9\n",
      "7\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "10\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "10\n",
      "3\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "3\n",
      "7\n",
      "4\n",
      "3\n",
      "10\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "10\n",
      "7\n",
      "8\n",
      "8\n",
      "4\n",
      "10\n",
      "5\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "9\n",
      "6\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "10\n",
      "7\n",
      "6\n",
      "10\n",
      "9\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "7\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "7\n",
      "9\n",
      "9\n",
      "10\n",
      "5\n",
      "8\n",
      "7\n",
      "8\n",
      "10\n",
      "9\n",
      "4\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "10\n",
      "6\n",
      "2\n",
      "6\n",
      "9\n",
      "3\n",
      "9\n",
      "8\n",
      "10\n",
      "7\n",
      "8\n",
      "5\n",
      "8\n",
      "5\n",
      "9\n",
      "7\n",
      "10\n",
      "9\n",
      "6\n",
      "5\n",
      "10\n",
      "8\n",
      "10\n",
      "8\n",
      "9\n",
      "10\n",
      "7\n",
      "10\n",
      "6\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "3\n",
      "7\n",
      "6\n",
      "10\n",
      "10\n",
      "8\n",
      "10\n",
      "10\n",
      "4\n",
      "8\n",
      "9\n",
      "5\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "5\n",
      "9\n",
      "8\n",
      "10\n",
      "9\n",
      "5\n",
      "5\n",
      "10\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "10\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "3\n",
      "10\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "5\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "5\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "1\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "10\n",
      "10\n",
      "6\n",
      "10\n",
      "2\n",
      "10\n",
      "6\n",
      "10\n",
      "9\n",
      "7\n",
      "8\n",
      "4\n",
      "10\n",
      "5\n",
      "7\n",
      "3\n",
      "10\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "3\n",
      "8\n",
      "4\n",
      "7\n",
      "6\n",
      "3\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "6\n",
      "10\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "2\n",
      "10\n",
      "9\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "4\n",
      "7\n",
      "10\n",
      "4\n",
      "5\n",
      "8\n",
      "9\n",
      "5\n",
      "9\n",
      "10\n",
      "8\n",
      "10\n",
      "4\n",
      "10\n",
      "9\n",
      "9\n",
      "7\n",
      "10\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "5\n",
      "9\n",
      "9\n",
      "4\n",
      "8\n",
      "7\n",
      "5\n",
      "8\n",
      "5\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "6\n",
      "7\n",
      "10\n",
      "9\n",
      "4\n",
      "5\n",
      "9\n",
      "7\n",
      "6\n",
      "8\n",
      "10\n",
      "10\n",
      "4\n",
      "9\n",
      "9\n",
      "10\n",
      "7\n",
      "5\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "7\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "6\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "9\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "6\n",
      "10\n",
      "8\n",
      "8\n",
      "11\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "6\n",
      "9\n",
      "8\n",
      "9\n",
      "10\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "9\n",
      "5\n",
      "8\n",
      "8\n",
      "7\n",
      "5\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "10\n",
      "10\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "10\n",
      "9\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "9\n",
      "6\n",
      "10\n",
      "7\n",
      "7\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "9\n",
      "7\n",
      "8\n",
      "4\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "7\n",
      "10\n",
      "6\n",
      "10\n",
      "8\n",
      "9\n",
      "10\n",
      "4\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "4\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "10\n",
      "5\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "11\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "7\n",
      "8\n",
      "4\n",
      "5\n",
      "8\n",
      "10\n",
      "9\n",
      "8\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "5\n",
      "9\n",
      "7\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "4\n",
      "8\n",
      "8\n",
      "6\n",
      "9\n",
      "10\n",
      "8\n",
      "10\n",
      "5\n",
      "7\n",
      "10\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "9\n",
      "9\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "7\n",
      "9\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "10\n",
      "5\n",
      "7\n",
      "9\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "10\n",
      "6\n",
      "9\n",
      "5\n",
      "6\n",
      "6\n",
      "10\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "8\n",
      "10\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iterator:\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        rounded_preds = torch.round(predictions)\n",
    "        for x in rounded_preds:\n",
    "            val = int(x.tolist())\n",
    "            print(max(val, 1))\n",
    "        \n",
    "        #print(batch.label)\n",
    "        #print(rounded_preds, '\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
